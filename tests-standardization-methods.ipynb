{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as data # Sample datasets\n",
    "from sklearn import svm # SVM Classifier\n",
    "from sklearn.naive_bayes import GaussianNB # Naive Bayes Classifier\n",
    "from sklearn.neural_network import MLPClassifier # MLP Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier # K-Neighbors Classifier\n",
    "from sklearn.neighbors import NearestCentroid # Nearest Centroid Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score # Cross Validation\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_QDA(X,y):\n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "\n",
    "def test_Forest(X,y):\n",
    "    clf = RandomForestClassifier(n_estimators=10)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "\n",
    "def test_Tree(X,y):\n",
    "    clf = DecisionTreeClassifier(max_depth=5)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "\n",
    "def test_KNC(X,y):\n",
    "    clf = KNeighborsClassifier(3).fit(X, y)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "\n",
    "def test_NCC(X,y):\n",
    "    clf = NearestCentroid().fit(X, y)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "\n",
    "def test_SVC(X,y):\n",
    "    clf = svm.SVC(kernel='linear', C=0.1).fit(X,y)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "    \n",
    "def test_SVC_RBF(X,y):\n",
    "    clf = svm.SVC(kernel='rbf', C=1).fit(X,y)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "    \n",
    "def test_Bayes(X,y):\n",
    "    clf = GaussianNB().fit(X,y)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "    \n",
    "def test_MLP(X, y):\n",
    "    clf = MLPClassifier(alpha=1, max_iter=1000).fit(X, y)\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def standardize_method_1(x, maxValue=5):\n",
    "    results = np.zeros([x.shape[0], 3])\n",
    "    for i,value in enumerate(x):\n",
    "        for base in range(2,maxValue+1):      \n",
    "            if value == 0:\n",
    "                coeff, base, exponent = 0, 0, 0\n",
    "            else:\n",
    "                coeff, value = np.sign(value), abs(value)\n",
    "                exponent = math.log(value,base)\n",
    "            absExponent = abs(exponent)\n",
    "            if absExponent <= maxValue:\n",
    "                results[i:] = [coeff, base, exponent]\n",
    "                break\n",
    "    return results\n",
    "\n",
    "def standardize_method_2(x, width=5):\n",
    "    results = np.zeros([x.shape[0], width])\n",
    "    for i,value in enumerate(x):\n",
    "        char_list = np.array(list(str(int(value*(10**width)))[:width]))\n",
    "        char_list = np.pad(char_list,(width-len(char_list),0))\n",
    "        results[i:] = [int(c) for c in char_list]\n",
    "    return results\n",
    "\n",
    "def standardize_method_3(x):\n",
    "    results = np.zeros([x.shape[0], 2])\n",
    "    for i,value in enumerate(x):\n",
    "        counter = 0\n",
    "        sign = np.sign(value)\n",
    "        value = abs(value)\n",
    "        while True:\n",
    "            if value >= 0 and value <= 1:\n",
    "                break\n",
    "            value = np.cbrt(value)\n",
    "            counter = counter+1\n",
    "        results[i:] = [sign*counter, np.modf(value)[0]*10]\n",
    "    return results\n",
    "\n",
    "def standardize_method_4(x):\n",
    "    results = np.zeros([x.shape[0], 2])\n",
    "    for i,value in enumerate(x):\n",
    "        if value == 0:\n",
    "            coeff, exponent = 0, 0\n",
    "        else:\n",
    "            coeff, value = np.sign(value), abs(value)\n",
    "            exponent = math.log(value,2)\n",
    "        results[i:] = [coeff, exponent]\n",
    "    return results\n",
    "\n",
    "def standardize_method_5(x):\n",
    "    return x/(max(x[0:5])+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = []\n",
    "y_ = []\n",
    "# House-prices dataset \n",
    "X_.append(data.load_boston()[\"data\"])\n",
    "y_.append(data.load_boston()[\"target\"] > 20)\n",
    "# Iris dataset\n",
    "X_.append(data.load_iris()[\"data\"])\n",
    "y_.append(data.load_iris()[\"target\"] == 1)\n",
    "#functions_list = [test_SVC, test_SVC_RBF, test_Bayes, test_KNC, test_NCC, test_Tree, test_Forest]\n",
    "functions_list = [test_SVC, test_SVC_RBF, test_Bayes, test_KNC, test_NCC, test_Tree, test_Forest]\n",
    "df_res = pd.DataFrame(columns=[\"Function\",\"Dataframe\",\"Standard?\",\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test without standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 617 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for i, (X, y) in enumerate(zip(X_, y_)):\n",
    "    for func in functions_list:\n",
    "        scores = func(X,y)\n",
    "        df_res.loc[len(df_res.index)] = np.concatenate([[func.__name__, i, \"No\", np.mean(scores)],scores])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with standardize_method_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 360 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 12)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "maxValue = 10\n",
    "for i, (X, y) in enumerate(zip(X_, y_)):\n",
    "    X2 = np.zeros([X.shape[0], X.shape[1]*3])\n",
    "    for j in range(X.shape[1]):\n",
    "        X2[:,3*j:3*j+3] = standardize_method_1(X[:,j], maxValue)\n",
    "    #X2 = Normalizer().fit(X2).transform(X2)\n",
    "    for func in functions_list:        \n",
    "        scores = func(X2,y)\n",
    "        df_res.loc[len(df_res.index)] = np.concatenate([[func.__name__, i, \"1\", np.mean(scores)],scores])\n",
    "np.shape(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with standardize_method_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 20)\n",
      "Wall time: 746 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "width = 5\n",
    "for i, (X, y) in enumerate(zip(X_, y_)):\n",
    "    X3 = np.zeros([X.shape[0], X.shape[1]*width])\n",
    "    for j in range(X.shape[1]):        \n",
    "        X3[:,width*j:width*j+width] = standardize_method_2(X[:,j], width)\n",
    "    #X3 = Normalizer().fit(X3).transform(X3)\n",
    "    for func in functions_list:\n",
    "        scores = func(X3,y)\n",
    "        df_res.loc[len(df_res.index)] = np.concatenate([[func.__name__, i, \"2\", np.mean(scores)],scores])\n",
    "print(np.shape(X3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with standardize_method_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 680 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 8)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for i, (X, y) in enumerate(zip(X_, y_)):\n",
    "    X4 = np.zeros([X.shape[0], X.shape[1]*2])\n",
    "    for j in range(X.shape[1]):\n",
    "        X4[:,2*j:2*j+2] = standardize_method_3(X[:,j])\n",
    "    #X4 = Normalizer().fit(X4).transform(X4)\n",
    "    for func in functions_list:        \n",
    "        scores = func(X4,y)\n",
    "        df_res.loc[len(df_res.index)] = np.concatenate([[func.__name__, i, \"3\", np.mean(scores)],scores])\n",
    "np.shape(X4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with standardize_method_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 339 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 8)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for i, (X, y) in enumerate(zip(X_, y_)):\n",
    "    X5 = np.zeros([X.shape[0], X.shape[1]*2])\n",
    "    for j in range(X.shape[1]):\n",
    "        X5[:,2*j:2*j+2] = standardize_method_4(X[:,j])\n",
    "    #X5 = Normalizer().fit(X5).transform(X5)\n",
    "    for func in functions_list:        \n",
    "        scores = func(X5,y)\n",
    "        df_res.loc[len(df_res.index)] = np.concatenate([[func.__name__, i, \"4\", np.mean(scores)],scores])\n",
    "np.shape(X5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with standardize_method_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 293 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for i, (X, y) in enumerate(zip(X_, y_)):\n",
    "    X6 = np.zeros([X.shape[0], X.shape[1]])\n",
    "    for j in range(X.shape[1]):\n",
    "        X6[:,j] = standardize_method_5(X[:,j])\n",
    "    X6 = Normalizer().fit(X6).transform(X6)\n",
    "    for func in functions_list:        \n",
    "        scores = func(X6,y)\n",
    "        df_res.loc[len(df_res.index)] = np.concatenate([[func.__name__, i, \"5\", np.mean(scores)],scores])\n",
    "np.shape(X6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Dataframe</th>\n",
       "      <th>Standard?</th>\n",
       "      <th>Average</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Score5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_SVC</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.8141525917297612</td>\n",
       "      <td>0.8529411764705882</td>\n",
       "      <td>0.7128712871287128</td>\n",
       "      <td>0.7821782178217822</td>\n",
       "      <td>0.9801980198019802</td>\n",
       "      <td>0.7425742574257426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_SVC_RBF</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.7315084449621433</td>\n",
       "      <td>0.5882352941176471</td>\n",
       "      <td>0.6237623762376238</td>\n",
       "      <td>0.8118811881188119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6336633663366337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_Bayes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.7907202484954378</td>\n",
       "      <td>0.6862745098039216</td>\n",
       "      <td>0.801980198019802</td>\n",
       "      <td>0.8217821782178217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6435643564356436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_KNC</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.6860609590370802</td>\n",
       "      <td>0.5392156862745098</td>\n",
       "      <td>0.693069306930693</td>\n",
       "      <td>0.6831683168316832</td>\n",
       "      <td>0.9207920792079208</td>\n",
       "      <td>0.594059405940594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_NCC</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.7255678509027373</td>\n",
       "      <td>0.5882352941176471</td>\n",
       "      <td>0.6138613861386139</td>\n",
       "      <td>0.8118811881188119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6138613861386139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>test_Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>test_KNC</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9733333333333334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9333333333333333</td>\n",
       "      <td>0.9666666666666667</td>\n",
       "      <td>0.9666666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>test_NCC</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6666666666666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6666666666666666</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>test_Tree</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9200000000000002</td>\n",
       "      <td>0.9666666666666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9333333333333333</td>\n",
       "      <td>0.9333333333333333</td>\n",
       "      <td>0.7666666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>test_Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9733333333333334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9333333333333333</td>\n",
       "      <td>0.9333333333333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Function Dataframe Standard?             Average              Score1  \\\n",
       "0       test_SVC         0        No  0.8141525917297612  0.8529411764705882   \n",
       "1   test_SVC_RBF         0        No  0.7315084449621433  0.5882352941176471   \n",
       "2     test_Bayes         0        No  0.7907202484954378  0.6862745098039216   \n",
       "3       test_KNC         0        No  0.6860609590370802  0.5392156862745098   \n",
       "4       test_NCC         0        No  0.7255678509027373  0.5882352941176471   \n",
       "..           ...       ...       ...                 ...                 ...   \n",
       "79    test_Bayes         1         5                0.82                 1.0   \n",
       "80      test_KNC         1         5  0.9733333333333334                 1.0   \n",
       "81      test_NCC         1         5  0.6666666666666667                 1.0   \n",
       "82     test_Tree         1         5  0.9200000000000002  0.9666666666666667   \n",
       "83   test_Forest         1         5  0.9733333333333334                 1.0   \n",
       "\n",
       "                Score2              Score3              Score4  \\\n",
       "0   0.7128712871287128  0.7821782178217822  0.9801980198019802   \n",
       "1   0.6237623762376238  0.8118811881188119                 1.0   \n",
       "2    0.801980198019802  0.8217821782178217                 1.0   \n",
       "3    0.693069306930693  0.6831683168316832  0.9207920792079208   \n",
       "4   0.6138613861386139  0.8118811881188119                 1.0   \n",
       "..                 ...                 ...                 ...   \n",
       "79                 1.0                 0.9                 0.6   \n",
       "80                 1.0  0.9333333333333333  0.9666666666666667   \n",
       "81                 1.0  0.6666666666666666  0.3333333333333333   \n",
       "82                 1.0  0.9333333333333333  0.9333333333333333   \n",
       "83                 1.0                 1.0  0.9333333333333333   \n",
       "\n",
       "                Score5  \n",
       "0   0.7425742574257426  \n",
       "1   0.6336633663366337  \n",
       "2   0.6435643564356436  \n",
       "3    0.594059405940594  \n",
       "4   0.6138613861386139  \n",
       "..                 ...  \n",
       "79                 0.6  \n",
       "80  0.9666666666666667  \n",
       "81  0.3333333333333333  \n",
       "82  0.7666666666666667  \n",
       "83  0.9333333333333333  \n",
       "\n",
       "[84 rows x 9 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the only exception of MLP classifier, standardization methods speeded up the learning time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_res[df_res[\"Standard?\"]==\"No\"].loc[:,[\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"]].reset_index(drop=True)\n",
    "df2 = df_res[df_res[\"Standard?\"]==\"1\"].loc[:,[\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"]].reset_index(drop=True)\n",
    "df3 = df_res[df_res[\"Standard?\"]==\"2\"].loc[:,[\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"]].reset_index(drop=True)\n",
    "df4 = df_res[df_res[\"Standard?\"]==\"3\"].loc[:,[\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"]].reset_index(drop=True)\n",
    "df5 = df_res[df_res[\"Standard?\"]==\"4\"].loc[:,[\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"]].reset_index(drop=True)\n",
    "df6 = df_res[df_res[\"Standard?\"]==\"5\"].loc[:,[\"Average\",\"Score1\",\"Score2\",\"Score3\",\"Score4\",\"Score5\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.ge(df1).sum()[\"Average\"]/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.ge(df1).sum()[\"Average\"]/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.ge(df1).sum()[\"Average\"]/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.ge(df1).sum()[\"Average\"]/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.ge(df1).sum()[\"Average\"]/len(df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featex",
   "language": "python",
   "name": "featex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
